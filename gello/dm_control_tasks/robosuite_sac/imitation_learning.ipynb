{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7978fadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No private macro file found!\n",
      "    It is recommended to use a private macro file\n",
      "    To setup, run: python /home/sj/Assistive_Feeding_Gello/robomimic/robomimic/scripts/setup_macros.py\n",
      ")\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import h5py\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import glob \n",
    "\n",
    "import torch\n",
    "\n",
    "import robomimic\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "import robomimic.utils.torch_utils as TorchUtils\n",
    "import robomimic.utils.tensor_utils as TensorUtils\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "from robomimic.envs.env_base import EnvBase\n",
    "from robomimic.algo import RolloutPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1a59bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2140,  0.2667,  0.2443],\n",
      "        [-0.2224,  0.2733,  0.2333],\n",
      "        [-0.2246,  0.2846,  0.2215],\n",
      "        [-0.2266,  0.2924,  0.2148],\n",
      "        [-0.2289,  0.2977,  0.2108],\n",
      "        [-0.2268,  0.3061,  0.2087],\n",
      "        [-0.2260,  0.3132,  0.2064],\n",
      "        [-0.2274,  0.3180,  0.2040],\n",
      "        [-0.2253,  0.3273,  0.2022],\n",
      "        [-0.2268,  0.3341,  0.1985],\n",
      "        [-0.2304,  0.3382,  0.1955],\n",
      "        [-0.2329,  0.3406,  0.1939],\n",
      "        [-0.2370,  0.3441,  0.1906],\n",
      "        [-0.2393,  0.3456,  0.1886],\n",
      "        [-0.2425,  0.3469,  0.1863],\n",
      "        [-0.2435,  0.3464,  0.1857],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_folder = \"/home/sj/Assistive_Feeding_Gello/csv/diffstartsamegoalsp100/pose5/test\"\n",
    "end_eff_folder = \"/home/sj/Assistive_Feeding_Gello/csv/diffstartsamegoalsp100/end_eff5/test\"\n",
    "\n",
    "csv_files = glob.glob(os.path.join(csv_folder, '*.csv'))\n",
    "end_eff_files = glob.glob(os.path.join(end_eff_folder, '*.csv'))\n",
    "\n",
    "low_dim_data = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for csv_file, end_eff_file in zip(csv_files, end_eff_files):\n",
    "        joint_data = pd.read_csv(csv_file, usecols=range(0, 6), engine='python').astype(np.float64)\n",
    "        end_eff_pos_data = pd.read_csv(end_eff_file, usecols=range(0, 3), engine='python').astype(np.float64)\n",
    "        end_eff_quat_data = pd.read_csv(end_eff_file, usecols=range(3, 7), engine='python').astype(np.float64)\n",
    "\n",
    "        joint_data = torch.tensor(joint_data.values).float().to(device)\n",
    "        end_eff_pos_data = torch.tensor(end_eff_pos_data.values).float().to(device)\n",
    "        end_eff_quat_data = torch.tensor(end_eff_quat_data.values).float().to(device)\n",
    "\n",
    "# obs = {\"robot0_joint_pos\": joint_data, \"robot0_eef_pos\": end_eff_pos_data, \"robot0_eef_quat\": end_eff_quat_data}\n",
    "# print(obs[\"robot0_joint_pos\"].shape, obs[\"robot0_eef_pos\"].shape, obs[\"robot0_eef_quat\"].shape)\n",
    "\n",
    "obs = {\"robot0_eef_pos\": end_eff_pos_data}\n",
    "print(obs[\"robot0_eef_pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01cb3dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sj/Assistive_Feeding_Gello/robomimic/robomimic/utils/file_utils.py\n"
     ]
    }
   ],
   "source": [
    "import robomimic.utils.file_utils as FileUtils\n",
    "\n",
    "print(FileUtils.policy_from_checkpoint.__code__.co_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7911d9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['robot0_eef_pos']\n",
      "using obs modality: rgb with keys: []\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n"
     ]
    }
   ],
   "source": [
    "# ckpt_path = \"/home/sj/assistive_feed_gello/Assistive_Feeding_Gello/robomimic/bc_trained_models/allready2/20240607064247/models/model_epoch_100.pth\"\n",
    "ckpt_path = \"/home/sj/Assistive_Feeding_Gello/robomimic/bc_trained_models/allready2/20240614134639/models/model_epoch_100.pth\"\n",
    "# Restore policy\n",
    "policy, ckpt_dict = FileUtils.policy_from_checkpoint(ckpt_path=ckpt_path, device=device, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b17bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "here\n",
      "Action [-0.23131675  0.273793    0.23785679] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.4235979   0.20831943  0.24414095] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.56953746  0.2224338   0.27900046] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.6734015   0.26450974  0.29984844] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.7412043   0.315152    0.30394134] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.78268415  0.36276838  0.29703942] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.8081849   0.40346107  0.28361663] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.82333386  0.43421897  0.2703569 ] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.83232355  0.45611784  0.256963  ] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.83781266  0.47212783  0.24487413] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.84108645  0.4835919   0.23518606] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.84284276  0.49115974  0.22786908] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.84374774  0.4959877   0.22267243] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.84427315  0.49912903  0.21907148] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.8445787   0.50117713  0.21664591] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.8447563   0.5024898   0.21505906] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.84485954  0.50332147  0.21404213] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.844921   0.503838   0.2134081] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.84495795  0.5041549   0.21302111] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.8449806   0.5043474   0.21278958] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.8449946   0.50446326  0.21265355] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.84500337  0.50453264  0.21257503] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.84500897  0.50457394  0.21253039] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.84501255  0.50459874  0.21250536] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.8450148   0.5046136   0.21249141] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.8450163   0.5046226   0.21248372] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.8450172   0.50462806  0.21247937] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.8450178   0.50463146  0.21247692] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.8450182   0.50463367  0.21247543] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.84501845  0.5046351   0.21247455] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(obs[\"robot0_eef_pos\"])):\n",
    "    obs_to_pass = {\"robot0_eef_pos\": obs[\"robot0_eef_pos\"][0]}\n",
    "    # obs_to_pass = {\"robot0_eef_pos\": torch.tensor(obs[\"robot0_eef_pos\"][0]).to(device)}\n",
    "    # print(obs_to_pass[\"robot0_eef_pos\"])\n",
    "    # policy, ckpt_dict = FileUtils.policy_from_checkpoint(ckpt_path=ckpt_path, device=device, verbose=True)\n",
    "    with torch.no_grad():\n",
    "        action = policy(obs_to_pass)\n",
    "        print(\"Action\", action, \"\\n\", \"robot0_eef_pos\", obs_to_pass[\"robot0_eef_pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186964bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(obs[\"robot0_joint_pos\"])):\n",
    "    obs_to_pass = {\"robot0_joint_pos\": obs[\"robot0_joint_pos\"][i], \"robot0_eef_pos\": obs[\"robot0_eef_pos\"][i], \"robot0_eef_quat\": obs[\"robot0_eef_quat\"][i]}\n",
    "    print(obs_to_pass[\"robot0_joint_pos\"])\n",
    "    action = policy(obs_to_pass)\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f238e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_from_policy(policy, obs):\n",
    "    # Get action from policy\n",
    "    action = policy(obs)\n",
    "    print(action)\n",
    "    return action\n",
    "\n",
    "for i in range(len(obs[\"robot0_eef_pos\"])):\n",
    "    if i==0:\n",
    "        obs_to_pass = {\"robot0_eef_pos\": obs[\"robot0_eef_pos\"]}\n",
    "        print(i, \"obs_to_pass\", obs_to_pass[\"robot0_eef_pos\"])\n",
    "        action = policy(obs_to_pass)\n",
    "        print(i, \"action\", action)\n",
    "        continue\n",
    "    print(\"i\", i)\n",
    "    obs_to_pass = {\"robot0_eef_pos\": action}\n",
    "    print(i, \"obs_to_pass\", obs_to_pass[\"robot0_eef_pos\"])\n",
    "    action = policy(obs_to_pass)\n",
    "    print(i, \"action\", action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"/home/sj/Downloads/split_part2.hdf5\"\n",
    "\n",
    "num = 2\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'a') as f:\n",
    "    # Iterate through each demo group\n",
    "    for demo_name in f[\"data\"].keys():\n",
    "        demo_group = f['data'][demo_name]\n",
    "        \n",
    "    # #     # Access the corner2_image dataset within the obs group of the demo group\n",
    "        image_data = demo_group['obs']['corner2_image'][:]\n",
    "        \n",
    "        # Perform the operation on the image array\n",
    "        image_data = np.array(image_data)\n",
    "\n",
    "        print(image_data.shape)\n",
    "\n",
    "        for i in range(14):\n",
    "            image_data = np.insert(image_data, num, image_data[num - 1], axis=0)\n",
    "            num += 2\n",
    "\n",
    "        num = 2\n",
    "\n",
    "        # Delete the existing corner2_image dataset\n",
    "        del demo_group['obs']['corner2_image']\n",
    "        \n",
    "        # Rename the \"images\" dataset as \"corner2_image\"\n",
    "        demo_group[\"obs\"].create_dataset(\"corner2_image\", data=image_data)\n",
    "\n",
    "\n",
    "    for demo_name in f[\"data\"].keys():\n",
    "        demo_group = f['data'][demo_name]        # Now working on manipulating the split_data\n",
    "\n",
    "        state_data = demo_group['states'][:]\n",
    "\n",
    "        num = 2\n",
    "\n",
    "        new_state_data = np.empty((state_data.shape[0] + 14, state_data.shape[1]))\n",
    "\n",
    "        for i in range(14):\n",
    "            state_data_plus1  = state_data[num+1]\n",
    "            state_data_minus1 = state_data[num-1]\n",
    "\n",
    "            new_state_data[num] = (state_data_plus1 + state_data_minus1) / 2\n",
    "\n",
    "            state_data = np.insert(state_data, num, new_state_data[num], axis=0)\n",
    "            num += 2\n",
    "\n",
    "        num = 2\n",
    "    # print(new_state_data.shape)\n",
    "    # print(state_data.shape)\n",
    "\n",
    "        # Delete the existing states dataset\n",
    "        del demo_group['states']\n",
    "\n",
    "        # # Create a new dataset with the new state data\n",
    "        demo_group.create_dataset(\"states\", data=new_state_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14499ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"/home/sj/Downloads/split_part1.hdf5\"\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'a') as f:\n",
    "    # Iterate through each demo group\n",
    "    for demo_name in f[\"data\"].keys():\n",
    "        demo_group = f['data'][demo_name]\n",
    "        \n",
    "    # #     # Access the corner2_image dataset within the obs group of the demo group\n",
    "        image_data = demo_group['obs']['corner2_image'][:]\n",
    "        \n",
    "        # Perform the operation on the image array\n",
    "        image_data = np.array(image_data)\n",
    "        labels = np.zeros((len(image_data), 1, 96, 96))\n",
    "        labels[14:] = 1\n",
    "        # image_data = np.concatenate((image_data, labels), axis=1)\n",
    "        # demo_group[\"obs\"].create_dataset(\"images\", data=image_data)\n",
    "\n",
    "        # # Delete the existing corner2_image dataset\n",
    "        # del demo_group['obs']['corner2_image']\n",
    "        \n",
    "        # # Rename the \"images\" dataset as \"corner2_image\"\n",
    "        # demo_group[\"obs\"].move(\"images\", \"corner2_image\")\n",
    "\n",
    "    #     print(image_data.shape)\n",
    "\n",
    "        # Now working on manipulating the split_data\n",
    "        state_data = demo_group['states'][-1, :3]\n",
    "        new_state_data = np.zeros((len(state_data), 3))\n",
    "        new_state_data[:] = state_data\n",
    "        # print(state_data)\n",
    "\n",
    "        new_state_data = np.concatenate((demo_group['states'], new_state_data), axis=-1)\n",
    "        print(new_state_data.shape)\n",
    "\n",
    "        # Delete the existing states dataset\n",
    "        del demo_group['states']\n",
    "\n",
    "        # Create a new dataset with the new state data\n",
    "        demo_group.create_dataset(\"states\", data=new_state_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0752d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "def test_connection(ip, port):\n",
    "    try:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            s.connect((ip, port))\n",
    "            print(f\"Successfully connected to {ip} on port {port}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect to {ip} on port {port}: {e}\")\n",
    "\n",
    "# IP address of the robot or gripper\n",
    "ip_address = \"192.168.77.21\"\n",
    "\n",
    "# Test common ports\n",
    "ports = [502, 29999, 30001, 30002, 30003]\n",
    "for port in ports:\n",
    "    test_connection(ip_address, port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "\n",
    "file_path = \"/home/sj/Assistive_Feeding_Gello/csv/train.log\"\n",
    "output_csv_path = \"/home/sj/Assistive_Feeding_Gello/csv/output.csv\"\n",
    "\n",
    "# Initialize a dictionary to store log entries\n",
    "log_entries = {}\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "loglist = [\"other/elapsed_time\", \"other/episode\", \"other/replay\", \"other/speed\", \"other/step\", \"other/train_step\", \"score/num_success\", \"score/score\"]\n",
    "loglist = np.array(loglist)\n",
    "loglist = np.char.strip(loglist)\n",
    "\n",
    "for line in lines:\n",
    "    stripped_line = line.strip()\n",
    "    match = re.search(r\"^(\\d+): (.+?)\\s+:\\s+([-+]?\\d*\\.\\d+|\\d+)$\", stripped_line)\n",
    "    if match:\n",
    "        timestep = int(match.group(1))\n",
    "        log_entry = match.group(2)\n",
    "        value = match.group(3)\n",
    "        if any(log in log_entry for log in loglist):\n",
    "            if timestep not in log_entries:\n",
    "                log_entries[timestep] = {}\n",
    "            log_entries[timestep][log_entry] = value\n",
    "\n",
    "# Ensure all timesteps have all log entries, filling missing ones with ''\n",
    "for timestep in log_entries:\n",
    "    for log in loglist:\n",
    "        if log not in log_entries[timestep]:\n",
    "            log_entries[timestep][log] = ''\n",
    "\n",
    "# Write the log entries to a CSV file\n",
    "with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=[\"timestep\"] + list(loglist))\n",
    "    writer.writeheader()\n",
    "    for timestep in sorted(log_entries.keys()):\n",
    "        row_data = {\"timestep\": timestep}\n",
    "        row_data.update(log_entries[timestep])\n",
    "        writer.writerow(row_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81dfdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file = \"/home/sj/Assistive_Feeding_Gello/csv/output.csv\"\n",
    "\n",
    "# Initialize lists to store data\n",
    "steps = []\n",
    "scores = []\n",
    "num_successes = []\n",
    "\n",
    "# Read data from CSV\n",
    "with open(csv_file, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        steps.append(int(row['other/step']))\n",
    "        scores.append(float(row['score/score']))\n",
    "        num_successes.append(int(row['score/num_success']))\n",
    "\n",
    "# Plotting score vs step\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(steps, scores, marker='o', linestyle='-', color='b', label='Score')\n",
    "plt.title('Score vs Step')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Score')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting num_success vs step\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(steps, num_successes, marker='o', linestyle='-', color='r', label='Num Success')\n",
    "plt.title('Num Success vs Step')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Num Success')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73de0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
